---
title: Hybrid Cloud As-A-Service
date: 2018-06-14
speaker: Benjamin Hindman and JÃ¶rg Schad, Mesosphere
eventlocation: San Francisco, CA, USA
eventimage: 2018-06-14_SF_hybrid_cloud.jpg
eventname: Bay Area Mesos User Group
category: Infrastructure
description: Hybrid Cloud Kubernetes, Spark, HDFS, Data Science As-A-Service
layout: event.jade
collection: events
lunr: true
---

# Abstract

For this meetup we are excited to be joined by two great speakers! Ben Hindman, Co-Founder of Mesosphere and Creator of Apache Mesos, and Joerg Schad, Technical Lead for Community Projects will be talking about running Kubernetes-As-A-Service alongside Apache Spark, HDFS, Data Science and more.

What You'll Learn At This Meetup:

1) Kubernetes-As-A-Service Alongside {Spark, HDFS, Data Science ..}-As-A-Service:

Kubernetes helps developers get their containers up and running. But what's the best way to run Kubernetes itself? What if you want to give each of your teams their own Kubernetes cluster?

Come here us talk about why and how we built Kubernetes-as-a-Service. Moreover, we'll describe the other "as-a-Service" options you can run along with Kubernetes, such as Kafka, Cassandra, HDFS, and Spark, in order to quickly get a stack deployed to help with your data engineering and data science projects. We'll finish it all off with a live demo that puts all the pieces together!

2) Kubeflow++:

In the second part we will look at how this concept extends to Data Science.

Kubeflow is makes it very easy for data scientist to build their own data science pipeline with Jupyter Notebooks, TensorFlow, TensorBoard and Model serving. However, to build a production grade data science pipeline requires some additional components.

As examples consider data preparation (which is frequently performed using Apache Spark or Apache Flink), data storage (using HDFS, Cassandra), or request streaming (using Apache Kafka).

The choice of tools often depends the concrete environment Kubeflow is running in: While Cloud Providers such as Google Cloud, AWS, or Azure have managed solutions for these challenges, an on-prem environment might require alternative Open-Source solutions.

So in this talk we look at building a complete deep learning pipeline around Kubeflow and answer topics such as:

* Data Preparation/Cleansing
* Data and Model Storage
* Model Serving
* Monitoring
* Infrastructure Management across multiple tenants

Event link: <a href="https://www.eventbrite.com/e/hybrid-cloud-kubernetes-spark-hdfs-data-science-as-a-service-tickets-46197733665">Hybrid Cloud {Kubernetes, Spark, HDFS, Data Science, ...} As-A-Service</a>

# Media
## Slides

<iframe src="https://docs.google.com/presentation/d/1zspl6zRgI28jZ8tYupyrzujveLsBFlHl4U61V3Ii1u0/embed?start=false&loop=false&delayms=3000" frameborder="0" width="640" height="389" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

## Photos

<a data-flickr-embed="true"  href="https://www.flickr.com/photos/pleia2/42088764684/in/dateposted/" title="Meetup at the @mesosphere office with @benh and @joerg_schad now! #dcos #kubernetes"><img src="https://farm2.staticflickr.com/1757/42088764684_00de4b5a0d_z.jpg" width="640" height="480" alt="Meetup at the @mesosphere office with @benh and @joerg_schad now! #dcos #kubernetes"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script>

<a data-flickr-embed="true"  href="https://www.flickr.com/photos/pleia2/27937158707/in/dateposted/" title="2018-06-14_07-12-08"><img src="https://farm2.staticflickr.com/1727/27937158707_caaeb5124a_z.jpg" width="640" height="480" alt="2018-06-14_07-12-08"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script>

<a data-flickr-embed="true"  href="https://www.flickr.com/photos/pleia2/41905778385/in/dateposted/" title="Now @benh deploys #kubernetes on #dcos"><img src="https://farm2.staticflickr.com/1724/41905778385_850c2ee279_z.jpg" width="640" height="480" alt="Now @benh deploys #kubernetes on #dcos"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script>
